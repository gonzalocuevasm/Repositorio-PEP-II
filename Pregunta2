#(24 puntos) A fin de determinar si es necesario establecer programas de entrenamiento diferenciados para clones y
#reclutas, Lord Vader quiere saber si es posible distinguir entre ambas clases de soldados con los datos actuales.
#Para ello,
#ha solicitado evaluar un modelo clasificador que contemple entre 2 y 5 variables predictoras. Considere que, para
#ser aceptable, el modelo:

#• Debe lograr una exactitud (accuracy) de al menos 0,8 en datos de prueba
#• No puede considerar casos con demasiada influencia (considerando la distancia de Cook)
#• No debe presentar autocorrelación (usando la prueba de Durbin-Watson para un retardo y un nivel de significación
#α = .01)
#• No debe presentar multicolinealidad severa (considerando el factor de inflación de la varianza, con un VIF promedio
#inferior a 1,03).

#Considere la semilla 3501 para obtener una muestra de 400 datos, 80% de los cuales serán empleados para ajustar el
#modelo y el 20% restante, para evaluarlo.


datos <- read.csv2(file.choose(),head=TRUE ,sep=";", stringsAsFactors = TRUE  )
#Justificacion de uso de metodo:
#Como nos solicitan incluir entre 2 a 5 variables predictorias se rechaza la opcion de utilizar una regresion lineal,
#y la variable a evaluar corresponde a una dicotimica, se decide implementar una regresion logistica.
#Variables:



set.seed (3501)


clones <- factor (datos$es_clon)


# Crear una variable indicadora para sexo , con valor 0
# para hombres y 1 , para mujeres .
tipo <- rep(1,length(clones))
tipo[ clones == "N"] <- 0

# Reemplazar la variable sexo por lavariable indicadora .
datos <- cbind ( datos , tipo )
datos [["es_clon"]] <- NULL



# Cargar los datos .

tipo <- factor ( datos$tipo )
datos$tipo <- NULL
datos <- cbind ( tipo , datos )

# Crear una variable indicadora para sexo , con valor 0
# para hombres y 1 , para mujeres .
# Separar conjuntos de entrenamiento y prueba .
n <- nrow ( datos )
n_entrenamiento <- floor (0.8 * n )
muestra <- sample.int ( n = n , size = n_entrenamiento , replace = FALSE )
entrenamiento <- datos [ muestra , ]
prueba <- datos [ - muestra , ]

# Ajustar modelo nulo .
nulo <- glm( tipo ~ 1 , family = binomial ( link = "logit") , data = entrenamiento )

# Ajustar modelo completo .
cat ("\n\n")
completo <- glm( tipo ~ . , family = binomial ( link = "logit") ,data = entrenamiento )

# Ajustar modelo con regresi ón escalonada .
cat (" Modelo con regresi ón escalonada \n")
cat (" - - - - - - - - - - -- - - - - - - - - - - - - - - - - - - - -- - - - - -\n")
mejor <- step ( nulo , scope = list ( lower = nulo , upper = completo ) , direction = "both", trace = 0)
print ( summary ( mejor ) )






