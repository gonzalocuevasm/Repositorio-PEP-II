#(24 puntos) A fin de determinar si es necesario establecer programas de entrenamiento diferenciados para clones y
#reclutas, Lord Vader quiere saber si es posible distinguir entre ambas clases de soldados con los datos actuales.
#Para ello,
#ha solicitado evaluar un modelo clasificador que contemple entre 2 y 5 variables predictoras. Considere que, para
#ser aceptable, el modelo:

#• Debe lograr una exactitud (accuracy) de al menos 0,8 en datos de prueba
#• No puede considerar casos con demasiada influencia (considerando la distancia de Cook)
#• No debe presentar autocorrelación (usando la prueba de Durbin-Watson para un retardo y un nivel de significación
#α = .01)
#• No debe presentar multicolinealidad severa (considerando el factor de inflación de la varianza, con un VIF promedio
#inferior a 1,03).

#Considere la semilla 3501 para obtener una muestra de 400 datos, 80% de los cuales serán empleados para ajustar el
#modelo y el 20% restante, para evaluarlo.


datos <- read.csv2(file.choose(),head=TRUE ,sep=";", stringsAsFactors = TRUE  )
#Justificación de uso de método:
#Como nos solicitan incluir entre 2 a 5 variables predictoras se rechaza la opción de utilizar una regresión lineal,
#y la variable a evaluar corresponde a una dicotómica, se decide implementar una regresión logística.
#Variables:


set.seed (3501)


clones <- factor (datos$es_clon)

# Crear una variable indicadora para clones llamada tipo , con valor 0
# para los que no son clonesy 1 , para los que son clones .
tipo <- rep(1,length(clones))
tipo[ clones == "N"] <- 0

# Reemplazar la variable tipo por la variable indicadora .
datos <- cbind ( datos , tipo )
datos[["es_clon"]] <- NULL

# Cargar los datos .
tipo <- factor(datos$tipo)
datos$tipo <- NULL
datos <- cbind(tipo,datos)

# Crear una variable indicadora para tipo , con valor 0
# para los que no son clones y 1 , para los que son clones .
# Separar conjuntos de entrenamiento y prueba .
n <- nrow ( datos )
n_entrenamiento <- floor (0.8 * n )
muestra <- sample.int ( n = n , size = n_entrenamiento , replace = FALSE )
entrenamiento <- datos [ muestra , ]
prueba <- datos [ - muestra , ]

# Ajustar modelo nulo .
nulo <- glm( tipo ~ 1 , family = binomial ( link = "logit") , data = entrenamiento )

# Ajustar modelo completo .
cat ("\n\n")
completo <- glm( tipo ~ . , family = binomial ( link = "logit") ,data = entrenamiento )

# Ajustar modelo con regresión escalonada .
cat (" Modelo con regresión escalonada \n")
cat (" - - - - - - - - - - -- - - - - - - - - - - - - - - - - - - - -- - - - - -\n")
mejor <- step ( nulo , scope = list ( lower = nulo , upper = completo ) , direction = "both", trace = 0)
print ( summary ( mejor ) )

# Ajustar modelo con la resistencia como predictor .
modelo1 <- glm( tipo ~ resistencia , family = binomial ( link = "logit") , data = entrenamiento )
print ( summary ( modelo1) )
aic_1 <- AIC ( modelo1)


# Ajustar modelo con el peso como predictor .
modelo2 <- glm( tipo ~ resistencia + velocidad, family = binomial ( link = "logit") , data = entrenamiento )
print ( summary ( modelo2) )
aic_2 <- AIC ( modelo2)

comparacion <- anova ( modelo1 , modelo2, test = "LRT")
cat("\nComparación modelo 1 con modelo 2:\n")
print(comparacion)

#Como AIC del modelo 2 es menor que AIC del mdoelo 1 y p = 2.2e-16 se afirma con un 95% de confianza que 
# el modelo 2 es mejor que el 1

# Ajustar modelo con el peso como predictor .
modelo3 <- glm( tipo ~ resistencia + velocidad + fuerza, family = binomial ( link = "logit") , data = entrenamiento )
print ( summary ( modelo3) )
aic_3 <- AIC ( modelo3)

comparacion <- anova ( modelo2 , modelo3, test = "LRT")
cat("\nComparación modelo 2 con modelo 3:\n")
print(comparacion)

#Como AIC del modelo 3 es menor que AIC del mdoelo 2 y p = 1.11e-05 se afirma con un 95% de confianza que 
# el modelo 3 es mejor que el 2


# Generación de data.Frame con los estadísticos para comprobar 
# la influencia de cada observación 
observaciones <- data.frame ( respuesta_predicha = fitted ( modelo3 ) ) 
observaciones [[" residuos_estandarizados "]] <- rstandard ( modelo3 ) 
observaciones [[" residuos_estudiantizados "]] <- rstudent ( modelo3 ) 
observaciones [[" distancia_Cook "]] <- cooks.distance ( modelo3 ) 
observaciones [[" dfbeta "]] <- dfbeta ( modelo3 ) 
observaciones [[" dffit "]] <- dffits ( modelo3 ) 
observaciones [[" apalancamiento "]] <- hatvalues ( modelo3 ) 
observaciones [[" covratio "]] <- covratio ( modelo3 ) 

cat (" Identificación de valores atípicos :\n") 
# Observaciones con residuos estandarizados fuera del 95 % esperado . 
atipicos <- which ( abs(observaciones [[" residuos_estandarizados "]]) > 1.96) 

cat ("- Residuos estandarizados fuera del 95 % esperado :",atipicos , "\n") 

# Observaciones con distancia de Cook mayor a uno. 
distanciaCook <- which ( observaciones [[" distancia_Cook "]] > 1) 
cat ("- Residuos con una distancia de Cook alta :",distanciaCook , "\n") 

# Observaciones con apalancamiento mayor igual al doble del 
# apalancamiento promedio . 
apal_medio <- ( ncol ( datos ) + 1) / nrow ( datos ) 
apalancamiento <- which ( observaciones [[" apalancamiento "]] > 2 * apal_medio ) 
cat ("- Residuos con apalancamiento fuera de rango :",apalancamiento , "\n") 


# Observaciones con DFBeta mayor o igual a 1. 
dfBeta <- which ( apply ( observaciones [[" dfbeta "]] >= 1, 1 , any) ) 
names( dfBeta ) <- NULL 
cat ("- Residuos con DFBeta >= 1:",dfBeta , "\n") 



#cat ("- Residuos con razón de covarianza fuera de rango :",covarianza , "\n") 

# Resumen de valores sospechosos . 
sospechosos <- c( atipicos , distanciaCook , apalancamiento ,dfBeta) 
sospechosos <- sort ( unique ( sospechosos ) ) 
cat ("\ nResumen de valores sospechosos :\n") 
cat (" Apalancamiento promedio :", apal_medio , "\n") 

#cat (" Intervalo razón de covarianza : [", inferior , "; ",superior , "]\n\n", sep = "") 

print ( round ( observaciones [ sospechosos , c(" distancia_Cook ", " apalancamiento ") ], 2) ) 

# La mayoría de los datos detectados como conflictivos presentan ciertas 
# condiciones que permiten no eliminarlos de la lista, pues en alguno con 
# con alto apalancamiento, su distancia de cook es baja o su nivel de 
# covarianza se encuentra dentro del rango óptimo. 

#Verificación de las condiciones 
# Comprobar independencia de los residuos . 
cat (" \nPrueba de Durbin - Watson para autocorrelaciones ") 
cat (" entre errores :\n") 
print ( durbinWatsonTest ( modelo3 ) ) 

# Con la prueba de Durbin-Watson se obtiene un p = 0.068, superior al nivel de significancia 
# lo que nos permite afirmar con un 95% de confianza que las residuos no estan correlacionados 


# Comprobar la multicolinealidad . 
vifs <- vif ( modelo3 ) 
cat ("\n Verificar la multicolinealidad :\n") 
cat ("- VIFs :\n") 
print ( vifs ) 
cat ("- Tolerancias :\n") 
print (1 / vifs ) 
cat ("- VIF medio :", mean ( vifs ) , "\n") 

# Cumple con  el criterio, todos los VIFS son menores a 5 y ademas, las toleracias 
# son superiores a 0.2 

# Evaluar el modelo 4 con el conjunto de entrenamiento
cat ("\n Evaluación del modelo a partir del conjunto de entrenamiento :\n")
probs_e <- predict ( modelo3 , entrenamiento , type = "response")

umbral <- 0.5
preds_e <- sapply ( probs_e , function (p) ifelse ( p >= umbral , "1", "0") )
preds_e <- factor ( preds_e , levels = levels ( datos[["tipo"]]) )

# Se obtiene el modelo roc del modelo 4 con el conjunto de entrenamiento
ROC_e <- roc ( entrenamiento[["tipo"]] , probs_e )
plot(ROC_e)

# Matriz de confusión del conjunto entrenamiento
matriz_e <- confusionMatrix ( preds_e , entrenamiento[["tipo"]])
print ( matriz_e )

# Evaluar el modelo 4 con el conjunto de prueba .
cat (" Evaluación del modelo a partir del conjunto de prueba :\n")
probs_p <- predict ( modelo3 , prueba , type = "response")

preds_p <- sapply ( probs_p , function ( p ) ifelse ( p >= umbral , "1", "0") )
preds_p <- factor ( preds_p , levels = levels ( datos [["tipo"]]) )

# Se obtiene el modelo roc del modelo 4 con el conjunto de prueba
ROC_p <- roc ( prueba[["tipo"]] , probs_p )
plot ( ROC_p )

# Matriz de confusión del conjunto de prueba
matriz_p <- confusionMatrix ( preds_p , prueba[["tipo"]])
print ( matriz_p )